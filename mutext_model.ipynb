{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7be5ef2-af15-4132-bf8b-d2091659d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b507a3-ae04-4ad7-94cf-f36eb6ffcfaf",
   "metadata": {},
   "source": [
    "# softmax test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0519e-a017-434e-b61e-c947a57d1087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41dd9d65-9bd1-429c-9608-1d555563f9c4",
   "metadata": {},
   "source": [
    "# Mutex Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9fa67a-2815-44a8-9aeb-03bf110e0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutex_block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mutex_block, self).__init__()\n",
    "        # self.batch = batch\n",
    "        # self.H = H\n",
    "        # self.C = C\n",
    "        # self.W = W\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, Frei, Frem):\n",
    "        batch, C, H, W = Frei.shape\n",
    "        \n",
    "        Fam = torch.subtract(Frei, Frem)\n",
    "        Fam = torch.pow(Fam, 2)\n",
    "        \n",
    "        #reshape\n",
    "        Fam = Fam.view(batch, C, H*W)\n",
    "        \n",
    "        #softmax\n",
    "        Fam = self.softmax(Fam)\n",
    "\n",
    "        #reshape\n",
    "        Fam = Fam.view(batch, C, H, W)\n",
    "        \n",
    "        #multiplication\n",
    "        Fam = torch.mul(Fam, Frem)\n",
    "        \n",
    "        return Fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa14fc-1970-41f0-8fcc-d4c35a30e9e4",
   "metadata": {},
   "source": [
    "# Fusion Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4671ab02-ef05-4ec9-a101-7757800d8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion_block(nn.Module):\n",
    "    def __init__(self, in_fc, out_fc, pool_size):\n",
    "        super(Fusion_block, self).__init__()\n",
    "        self.in_fc = in_fc\n",
    "        self.out_fc = out_fc\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.avgpool = nn.AvgPool2d(pool_size)\n",
    "        self.maxpool = nn.MaxPool2d(pool_size)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        # Set these parameters\n",
    "        self.fcC = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(in_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fcC_prim = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(out_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fcM = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(out_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fcN = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(out_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, Fam, Frem):\n",
    "        f_temp = torch.add(Fam, Frem)\n",
    "        # print(f'first add: {f_temp.shape}')\n",
    "        \n",
    "        avg_pool = self.avgpool(f_temp).squeeze()\n",
    "        max_pool = self.maxpool(f_temp).squeeze()\n",
    "        f_temp = torch.add(avg_pool, max_pool)\n",
    "        # print(f'add after poolings: {f_temp.shape}')\n",
    "        \n",
    "        f_temp = f_temp.view(f_temp.size(0), -1)\n",
    "        print(f'bifore first fc: {f_temp.shape}')\n",
    "        \n",
    "        \n",
    "        f_temp = self.fcC(f_temp)\n",
    "        print(f'after first fc: {f_temp.shape}')\n",
    "        f_temp = self.fcC_prim(f_temp)\n",
    "        print(f'after second fc: {f_temp.shape}')\n",
    "        \n",
    "        \n",
    "        fM = self.fcM(f_temp)\n",
    "        print(f'size of fM: {fM.shape}')\n",
    "        fN = self.fcN(f_temp)\n",
    "        print(f'size of fN: {fN.shape}')\n",
    "        \n",
    "        # unsqueeze\n",
    "        fM = torch.unsqueeze(fM, 0)\n",
    "        fN = torch.unsqueeze(fN, 0)\n",
    "        # print(f'unsqueeze fM: {fM.shape}\\nunsqueeze fN: {fN.shape}')\n",
    "        \n",
    "        # concatenate\n",
    "        z = torch.concat([fM, fN], dim=0)\n",
    "        # print(f'size of concat fM, fN: {z.shape}')\n",
    "        \n",
    "        # softmax\n",
    "        z = self.softmax(z)\n",
    "        # print(f'after softmax: {z.shape}')\n",
    "        \n",
    "        fM = z[0,...]\n",
    "        # print(f'separate fM: {fM.shape}')\n",
    "        fN = z[1,...]\n",
    "        # print(f'separate fN: {fN.shape}')\n",
    "        \n",
    "        \n",
    "        # print(f'size of fM after view: {fM.view(fM.size(0), fM.size(1), 1, 1).shape}')\n",
    "        \n",
    "        # fM --> [B, C]\n",
    "        # Fam --> [B, C, H, W]\n",
    "        Ffm_m = torch.mul(Fam, fM.view(fM.size(0), fM.size(1), 1, 1))\n",
    "        Ffm_n = torch.mul(Frem, fN.view(fN.size(0), fN.size(1), 1, 1))\n",
    "        \n",
    "        Ffm = torch.add(Ffm_m, Ffm_n)\n",
    "        \n",
    "        return Ffm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e13bb-5096-4690-849c-d4a2d5088cd5",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ba1d722-90d8-493d-b5c4-a3a9544016de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "              nn.Conv2d(in_planes, self.expansion*planes, \n",
    "                        kernel_size=1, stride=stride, bias=False),\n",
    "              nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5142352-4cbe-4390-a8ee-cffe8c9099bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, Mutex_attention, Fusion_attention, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.mutex_block_0 = Mutex_attention()\n",
    "        self.Fusion_block_0 = Fusion_attention(64, 64 , 54)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.mutex_block_1 = Mutex_attention()\n",
    "        self.Fusion_block_1 = Fusion_attention(256, 256, 54)\n",
    "        \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.mutex_block_2 = Mutex_attention()\n",
    "        self.Fusion_block_2 = Fusion_attention(512, 512, 27)\n",
    "        \n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.mutex_block_3 = Mutex_attention()\n",
    "        self.Fusion_block_3 = Fusion_attention(1024, 1024, 14)\n",
    "        \n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.mutex_block_4 = Mutex_attention()\n",
    "        self.Fusion_block_4 = Fusion_attention(2048, 2048, 7)\n",
    "        \n",
    "        # pooling\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        \n",
    "        self.fc_o_1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU())\n",
    "        self.fc_m_1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fc_o_2 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.ReLU())\n",
    "        self.fc_m_2 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.softmax_out = nn.Softmax(dim=1)\n",
    "        \n",
    "        # self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        # self.linear = nn.Linear(100352, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, mutex_x):\n",
    "        \n",
    "        \n",
    "        # Res_layer_0\n",
    "        print('Res_layer_0')\n",
    "        Frei = F.relu(self.layer0(x))\n",
    "        Frei = nn.MaxPool2d(kernel_size = 3, stride = 2)(Frei)\n",
    "        \n",
    "        Frem = F.relu(self.layer0(mutex_x))\n",
    "        Frem = nn.MaxPool2d(kernel_size = 3, stride = 2)(Frem)\n",
    "        \n",
    "        Fam = self.mutex_block_0(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_0(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        # print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_1\n",
    "        print('Res_layer_1')\n",
    "        \n",
    "        Frei = F.relu(self.layer1(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer1(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_1(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_1(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        # print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_2\n",
    "        print('Res_layer_2')\n",
    "        \n",
    "        Frei = F.relu(self.layer2(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer2(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_2(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_2(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        # print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_3\n",
    "        print('Res_layer_3')\n",
    "        \n",
    "        Frei = F.relu(self.layer3(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer3(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_3(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_3(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        # print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_4\n",
    "        print('Res_layer_4')\n",
    "        \n",
    "        Frei = F.relu(self.layer4(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer4(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_4(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_4(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        \n",
    "        #set Vi, Vm for calculate cosine loss\n",
    "        Vi = Fo.clone()\n",
    "        Vm = Fom.clone()\n",
    "        # print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # global pooling\n",
    "        Fo = self.avgpool(Fo).squeeze()\n",
    "        Fom = self.avgpool(Fom).squeeze()\n",
    "        # print(f'shape of Fo , Fm after pooling:\\n \\\n",
    "        #         {Fo.shape}, {Fom.shape}')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # final_fully_layer\n",
    "        Fo = self.fc_o_1(Fo)\n",
    "        Fom = self.fc_m_1(Fom)\n",
    "        \n",
    "        Fo = self.fc_o_2(Fo)\n",
    "        Fom = self.fc_m_2(Fom)\n",
    "        \n",
    "        Fo = self.softmax_out(Fo)\n",
    "        Fom = self.softmax_out(Fom)\n",
    "        \n",
    "        # print(f'Fo finel:{Fo.shape}')\n",
    "        # print(f'Fm finel:{Fom.shape}')\n",
    "        \n",
    "        # out = self.layer1(out)\n",
    "        # out = self.layer2(out)\n",
    "        # out = self.layer3(out)\n",
    "        # out = self.layer4(out)\n",
    "        # out = F.avg_pool2d(out, 4)\n",
    "        # out = out.view(out.size(0), -1)\n",
    "        # # print(out.shape)\n",
    "        # out = self.linear(out)\n",
    "        return Fo, Fom, Vi, Vm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd67322f-96a2-4936-8e9e-c57924fd559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 6, 3], Mutex_block, Fusion_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6e4f8ef-9172-4f87-a7d5-7704696a116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res_layer_0\n",
      "bifore first fc: torch.Size([16, 64])\n",
      "after first fc: torch.Size([16, 64])\n",
      "after second fc: torch.Size([16, 64])\n",
      "size of fM: torch.Size([16, 64])\n",
      "size of fN: torch.Size([16, 64])\n",
      "--------------------------------------------------\n",
      "Res_layer_1\n",
      "bifore first fc: torch.Size([16, 256])\n",
      "after first fc: torch.Size([16, 256])\n",
      "after second fc: torch.Size([16, 256])\n",
      "size of fM: torch.Size([16, 256])\n",
      "size of fN: torch.Size([16, 256])\n",
      "--------------------------------------------------\n",
      "Res_layer_2\n",
      "bifore first fc: torch.Size([16, 512])\n",
      "after first fc: torch.Size([16, 512])\n",
      "after second fc: torch.Size([16, 512])\n",
      "size of fM: torch.Size([16, 512])\n",
      "size of fN: torch.Size([16, 512])\n",
      "--------------------------------------------------\n",
      "Res_layer_3\n",
      "bifore first fc: torch.Size([16, 1024])\n",
      "after first fc: torch.Size([16, 1024])\n",
      "after second fc: torch.Size([16, 1024])\n",
      "size of fM: torch.Size([16, 1024])\n",
      "size of fN: torch.Size([16, 1024])\n",
      "--------------------------------------------------\n",
      "Res_layer_4\n",
      "bifore first fc: torch.Size([16, 2048])\n",
      "after first fc: torch.Size([16, 2048])\n",
      "after second fc: torch.Size([16, 2048])\n",
      "size of fM: torch.Size([16, 2048])\n",
      "size of fN: torch.Size([16, 2048])\n",
      "--------------------------------------------------\n",
      "torch.Size([16, 2048, 7, 7])\n",
      "torch.Size([16, 2048, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 2]), torch.Size([16, 2]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fo, Fom, Vi, Vm = model(torch.randn(16, 3, 224, 224), torch.randn(16, 3, 224, 224))\n",
    "print(Vi.shape)\n",
    "print(Vm.shape)\n",
    "Fo.shape, Fom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4e06b5b-1c8f-43cb-9f76-cc4524d7d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = ['ct_image', 'mutex_image']\n",
    "output_names = ['Fo', 'Fom']\n",
    "torch.onnx.export(model, (torch.randn(16, 3, 224, 224), torch.randn(16, 3, 224, 224)), 'final_model.onnx', input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9982f00-ac0e-43e5-8a5c-6afc010a7b95",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a5ffb8-3b7f-4fc1-ae5e-e2fa4cea5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "448cee9c-aa40-4c7f-9b21-de4ac15b638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_i = torch.randint(0, 2, (16,))\n",
    "labels_x = torch.randint(0, 2, (16,))\n",
    "# labels_onehot = F.one_hot(labels).squeeze()\n",
    "image_i = torch.rand(16, 3, 224, 224)\n",
    "image_x = torch.rand(16, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a38495a7-e04a-48f0-87aa-42fdd75c3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fo, Fom, Vi, Vm = model(image_i, image_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c43d90af-773c-4892-86ca-edd8229e8b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eb78a01-d786-422c-a28b-7bd7254d2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, weight_decay = 0.005, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4e27ff2-8b41-4d99-a0ff-603526552cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial losses\n",
    "Lce_ = nn.CrossEntropyLoss()\n",
    "Lcs_ = nn.CosineSimilarity(dim=1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71eee93a-038b-4ca7-89d8-a6d99ebbb7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6745, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6917, grad_fn=<NllLossBackward0>),\n",
       " tensor(1.3662, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate losses\n",
    "L1 = Lce_(Fo, labels_i)\n",
    "L2 = Lce_(Fom, labels_x)\n",
    "Lce = L1 + L2\n",
    "(L1, L2, Lce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29acc84f-5dc2-4fcd-9fad-3067f1fae7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcs = torch.mean(Lcs_(Vi.view(Vi.size(0), -1), Vm.view(Vm.size(0), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1804d44c-d190-4e24-ae8b-ed7abbae2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lce_exp = torch.exp(1/Lce)\n",
    "Lcs_exp = torch.exp(1/Lcs)\n",
    "a1 = Lce_exp / (Lce_exp + Lcs_exp)\n",
    "a2 = Lcs_exp / (Lce_exp + Lcs_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "889c7dde-810c-4102-bd26-83838d31fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (a1 * Lce) + (a2 * Lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72962f0-8e98-461a-90ef-37567c3b7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b7076-04c2-416c-9bf7-fe2432066f96",
   "metadata": {},
   "source": [
    "# Loss Fusnctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cab235d3-014d-4aae-9685-05e203da265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(16, 20, 7, 7)\n",
    "y = torch.rand(16, 20, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87c68184-4450-47fe-82f6-4e620b53871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(x.size(0), -1)\n",
    "y = y.view(y.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ebe8411-78b7-4e8a-98e5-a5396b4c3ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 980]) torch.Size([16, 980])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1eaad8d-2632-4dbc-b427-0879916149de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed77754a-a645-4f95-991b-e99b5a0cbadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7478, 0.7598, 0.7650, 0.7458, 0.7323, 0.7597, 0.7598, 0.7419, 0.7604,\n",
       "        0.7672, 0.7420, 0.7642, 0.7558, 0.7374, 0.7600, 0.7442])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78814ae6-f2bf-40be-a58f-f5617b338400",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cdc7e39-c881-4a9e-bf92-bed01c845da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47922500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958c336-1f97-4d0f-8746-4b7296ba26a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
