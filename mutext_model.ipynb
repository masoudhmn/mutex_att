{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7be5ef2-af15-4132-bf8b-d2091659d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b507a3-ae04-4ad7-94cf-f36eb6ffcfaf",
   "metadata": {},
   "source": [
    "# softmax test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0519e-a017-434e-b61e-c947a57d1087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41dd9d65-9bd1-429c-9608-1d555563f9c4",
   "metadata": {},
   "source": [
    "# Mutex Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9fa67a-2815-44a8-9aeb-03bf110e0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutex_block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mutex_block, self).__init__()\n",
    "        # self.batch = batch\n",
    "        # self.H = H\n",
    "        # self.C = C\n",
    "        # self.W = W\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, Frei, Frem):\n",
    "        batch, C, H, W = Frei.shape\n",
    "        \n",
    "        Fam = torch.subtract(Frei, Frem)\n",
    "        Fam = torch.pow(Fam, 2)\n",
    "        \n",
    "        #reshape\n",
    "        Fam = Fam.view(batch, C, H*W)\n",
    "        \n",
    "        #softmax\n",
    "        Fam = self.softmax(Fam)\n",
    "\n",
    "        #reshape\n",
    "        Fam = Fam.view(batch, C, H, W)\n",
    "        \n",
    "        #multiplication\n",
    "        Fam = torch.mul(Fam, Frem)\n",
    "        \n",
    "        return Fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa14fc-1970-41f0-8fcc-d4c35a30e9e4",
   "metadata": {},
   "source": [
    "# Fusion Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4671ab02-ef05-4ec9-a101-7757800d8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion_block(nn.Module):\n",
    "    def __init__(self, in_fc, out_fc, pool_size):\n",
    "        super(Fusion_block, self).__init__()\n",
    "        self.in_fc = in_fc\n",
    "        self.out_fc = out_fc\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.avgpool = nn.AvgPool2d(pool_size)\n",
    "        self.maxpool = nn.MaxPool2d(pool_size)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        # Set these parameters\n",
    "        self.fcC = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(in_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fcC_prim = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(out_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fcM = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(out_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fcN = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(out_fc, out_fc),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, Fam, Frem):\n",
    "        f_temp = torch.add(Fam, Frem)\n",
    "        print(f'first add: {f_temp.shape}')\n",
    "        \n",
    "        avg_pool = self.avgpool(f_temp).squeeze()\n",
    "        max_pool = self.maxpool(f_temp).squeeze()\n",
    "        f_temp = torch.add(avg_pool, max_pool)\n",
    "        print(f'add after poolings: {f_temp.shape}')\n",
    "        \n",
    "        f_temp = f_temp.view(f_temp.size(0), -1)\n",
    "        print(f'bifore first fc: {f_temp.shape}')\n",
    "        \n",
    "        \n",
    "        f_temp = self.fcC(f_temp)\n",
    "        print(f'after first fc: {f_temp.shape}')\n",
    "        f_temp = self.fcC_prim(f_temp)\n",
    "        print(f'after second fc: {f_temp.shape}')\n",
    "        \n",
    "        \n",
    "        fM = self.fcM(f_temp)\n",
    "        print(f'size of fM: {fM.shape}')\n",
    "        fN = self.fcN(f_temp)\n",
    "        print(f'size of fN: {fN.shape}')\n",
    "        \n",
    "        # unsqueeze\n",
    "        fM = torch.unsqueeze(fM, 0)\n",
    "        fN = torch.unsqueeze(fN, 0)\n",
    "        print(f'unsqueeze fM: {fM.shape}\\nunsqueeze fN: {fN.shape}')\n",
    "        \n",
    "        # concatenate\n",
    "        z = torch.concat([fM, fN], dim=0)\n",
    "        print(f'size of concat fM, fN: {z.shape}')\n",
    "        \n",
    "        # softmax\n",
    "        z = self.softmax(z)\n",
    "        print(f'after softmax: {z.shape}')\n",
    "        \n",
    "        fM = z[0,...]\n",
    "        print(f'separate fM: {fM.shape}')\n",
    "        fN = z[1,...]\n",
    "        print(f'separate fN: {fN.shape}')\n",
    "        \n",
    "        \n",
    "        print(f'size of fM after view: {fM.view(fM.size(0), fM.size(1), 1, 1).shape}')\n",
    "        \n",
    "        # fM --> [B, C]\n",
    "        # Fam --> [B, C, H, W]\n",
    "        Ffm_m = torch.mul(Fam, fM.view(fM.size(0), fM.size(1), 1, 1))\n",
    "        Ffm_n = torch.mul(Frem, fN.view(fN.size(0), fN.size(1), 1, 1))\n",
    "        \n",
    "        Ffm = torch.add(Ffm_m, Ffm_n)\n",
    "        \n",
    "        return Ffm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e13bb-5096-4690-849c-d4a2d5088cd5",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba1d722-90d8-493d-b5c4-a3a9544016de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "              nn.Conv2d(in_planes, self.expansion*planes, \n",
    "                        kernel_size=1, stride=stride, bias=False),\n",
    "              nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5142352-4cbe-4390-a8ee-cffe8c9099bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, Mutex_attention, Fusion_attention, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.mutex_block_0 = Mutex_attention()\n",
    "        self.Fusion_block_0 = Fusion_attention(64, 64 , 54)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.mutex_block_1 = Mutex_attention()\n",
    "        self.Fusion_block_1 = Fusion_attention(256, 256, 54)\n",
    "        \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.mutex_block_2 = Mutex_attention()\n",
    "        self.Fusion_block_2 = Fusion_attention(512, 512, 27)\n",
    "        \n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.mutex_block_3 = Mutex_attention()\n",
    "        self.Fusion_block_3 = Fusion_attention(1024, 1024, 14)\n",
    "        \n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.mutex_block_4 = Mutex_attention()\n",
    "        self.Fusion_block_4 = Fusion_attention(2048, 2048, 7)\n",
    "        \n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        # self.linear = nn.Linear(100352, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, mutex_x):\n",
    "        \n",
    "        \n",
    "        # Res_layer_0\n",
    "        print('Res_layer_0')\n",
    "        Frei = F.relu(self.layer0(x))\n",
    "        Frei = nn.MaxPool2d(kernel_size = 3, stride = 2)(Frei)\n",
    "        \n",
    "        Frem = F.relu(self.layer0(mutex_x))\n",
    "        Frem = nn.MaxPool2d(kernel_size = 3, stride = 2)(Frem)\n",
    "        \n",
    "        Fam = self.mutex_block_0(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_0(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_1\n",
    "        print('Res_layer_1')\n",
    "        \n",
    "        Frei = F.relu(self.layer1(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer1(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_1(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_1(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_2\n",
    "        print('Res_layer_2')\n",
    "        \n",
    "        Frei = F.relu(self.layer2(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer2(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_2(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_2(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_3\n",
    "        print('Res_layer_3')\n",
    "        \n",
    "        Frei = F.relu(self.layer3(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer3(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_3(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_3(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Res_layer_4\n",
    "        print('Res_layer_4')\n",
    "        \n",
    "        Frei = F.relu(self.layer4(Fi))\n",
    "        \n",
    "        Frem = F.relu(self.layer4(Fm))\n",
    "        \n",
    "        Fam = self.mutex_block_4(Frei, Frem)\n",
    "        \n",
    "        Fom = self.Fusion_block_4(Fam, Frem)\n",
    "        \n",
    "        Fo = Frei\n",
    "        \n",
    "        # Set names\n",
    "        Fi = Fo\n",
    "        Fm = Fom\n",
    "        print(f'shape of Fo is: {Fo.shape}')\n",
    "        print(50*'-')\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # out = self.layer1(out)\n",
    "        # out = self.layer2(out)\n",
    "        # out = self.layer3(out)\n",
    "        # out = self.layer4(out)\n",
    "        # out = F.avg_pool2d(out, 4)\n",
    "        # out = out.view(out.size(0), -1)\n",
    "        # # print(out.shape)\n",
    "        # out = self.linear(out)\n",
    "        return Fo, Fom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd67322f-96a2-4936-8e9e-c57924fd559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 6, 3], Mutex_block, Fusion_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e4f8ef-9172-4f87-a7d5-7704696a116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res_layer_0\n",
      "first add: torch.Size([16, 64, 54, 54])\n",
      "add after poolings: torch.Size([16, 64])\n",
      "bifore first fc: torch.Size([16, 64])\n",
      "after first fc: torch.Size([16, 64])\n",
      "after second fc: torch.Size([16, 64])\n",
      "size of fM: torch.Size([16, 64])\n",
      "size of fN: torch.Size([16, 64])\n",
      "unsqueeze fM: torch.Size([1, 16, 64])\n",
      "unsqueeze fN: torch.Size([1, 16, 64])\n",
      "size of concat fM, fN: torch.Size([2, 16, 64])\n",
      "after softmax: torch.Size([2, 16, 64])\n",
      "separate fM: torch.Size([16, 64])\n",
      "separate fN: torch.Size([16, 64])\n",
      "size of fM after view: torch.Size([16, 64, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 64, 54, 54])\n",
      "--------------------------------------------------\n",
      "Res_layer_1\n",
      "first add: torch.Size([16, 256, 54, 54])\n",
      "add after poolings: torch.Size([16, 256])\n",
      "bifore first fc: torch.Size([16, 256])\n",
      "after first fc: torch.Size([16, 256])\n",
      "after second fc: torch.Size([16, 256])\n",
      "size of fM: torch.Size([16, 256])\n",
      "size of fN: torch.Size([16, 256])\n",
      "unsqueeze fM: torch.Size([1, 16, 256])\n",
      "unsqueeze fN: torch.Size([1, 16, 256])\n",
      "size of concat fM, fN: torch.Size([2, 16, 256])\n",
      "after softmax: torch.Size([2, 16, 256])\n",
      "separate fM: torch.Size([16, 256])\n",
      "separate fN: torch.Size([16, 256])\n",
      "size of fM after view: torch.Size([16, 256, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 256, 54, 54])\n",
      "--------------------------------------------------\n",
      "Res_layer_2\n",
      "first add: torch.Size([16, 512, 27, 27])\n",
      "add after poolings: torch.Size([16, 512])\n",
      "bifore first fc: torch.Size([16, 512])\n",
      "after first fc: torch.Size([16, 512])\n",
      "after second fc: torch.Size([16, 512])\n",
      "size of fM: torch.Size([16, 512])\n",
      "size of fN: torch.Size([16, 512])\n",
      "unsqueeze fM: torch.Size([1, 16, 512])\n",
      "unsqueeze fN: torch.Size([1, 16, 512])\n",
      "size of concat fM, fN: torch.Size([2, 16, 512])\n",
      "after softmax: torch.Size([2, 16, 512])\n",
      "separate fM: torch.Size([16, 512])\n",
      "separate fN: torch.Size([16, 512])\n",
      "size of fM after view: torch.Size([16, 512, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 512, 27, 27])\n",
      "--------------------------------------------------\n",
      "Res_layer_3\n",
      "first add: torch.Size([16, 1024, 14, 14])\n",
      "add after poolings: torch.Size([16, 1024])\n",
      "bifore first fc: torch.Size([16, 1024])\n",
      "after first fc: torch.Size([16, 1024])\n",
      "after second fc: torch.Size([16, 1024])\n",
      "size of fM: torch.Size([16, 1024])\n",
      "size of fN: torch.Size([16, 1024])\n",
      "unsqueeze fM: torch.Size([1, 16, 1024])\n",
      "unsqueeze fN: torch.Size([1, 16, 1024])\n",
      "size of concat fM, fN: torch.Size([2, 16, 1024])\n",
      "after softmax: torch.Size([2, 16, 1024])\n",
      "separate fM: torch.Size([16, 1024])\n",
      "separate fN: torch.Size([16, 1024])\n",
      "size of fM after view: torch.Size([16, 1024, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 1024, 14, 14])\n",
      "--------------------------------------------------\n",
      "Res_layer_4\n",
      "first add: torch.Size([16, 2048, 7, 7])\n",
      "add after poolings: torch.Size([16, 2048])\n",
      "bifore first fc: torch.Size([16, 2048])\n",
      "after first fc: torch.Size([16, 2048])\n",
      "after second fc: torch.Size([16, 2048])\n",
      "size of fM: torch.Size([16, 2048])\n",
      "size of fN: torch.Size([16, 2048])\n",
      "unsqueeze fM: torch.Size([1, 16, 2048])\n",
      "unsqueeze fN: torch.Size([1, 16, 2048])\n",
      "size of concat fM, fN: torch.Size([2, 16, 2048])\n",
      "after softmax: torch.Size([2, 16, 2048])\n",
      "separate fM: torch.Size([16, 2048])\n",
      "separate fN: torch.Size([16, 2048])\n",
      "size of fM after view: torch.Size([16, 2048, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 2048, 7, 7])\n",
      "--------------------------------------------------\n",
      "torch.Size([16, 2048, 7, 7])\n",
      "torch.Size([16, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "Fo, Fom = model(torch.randn(16, 3, 224, 224), torch.randn(16, 3, 224, 224))\n",
    "print(Fo.shape)\n",
    "print(Fom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e06b5b-1c8f-43cb-9f76-cc4524d7d310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res_layer_0\n",
      "first add: torch.Size([16, 64, 54, 54])\n",
      "add after poolings: torch.Size([16, 64])\n",
      "bifore first fc: torch.Size([16, 64])\n",
      "after first fc: torch.Size([16, 64])\n",
      "after second fc: torch.Size([16, 64])\n",
      "size of fM: torch.Size([16, 64])\n",
      "size of fN: torch.Size([16, 64])\n",
      "unsqueeze fM: torch.Size([1, 16, 64])\n",
      "unsqueeze fN: torch.Size([1, 16, 64])\n",
      "size of concat fM, fN: torch.Size([2, 16, 64])\n",
      "after softmax: torch.Size([2, 16, 64])\n",
      "separate fM: torch.Size([16, 64])\n",
      "separate fN: torch.Size([16, 64])\n",
      "size of fM after view: torch.Size([16, 64, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 64, 54, 54])\n",
      "--------------------------------------------------\n",
      "Res_layer_1\n",
      "first add: torch.Size([16, 256, 54, 54])\n",
      "add after poolings: torch.Size([16, 256])\n",
      "bifore first fc: torch.Size([16, 256])\n",
      "after first fc: torch.Size([16, 256])\n",
      "after second fc: torch.Size([16, 256])\n",
      "size of fM: torch.Size([16, 256])\n",
      "size of fN: torch.Size([16, 256])\n",
      "unsqueeze fM: torch.Size([1, 16, 256])\n",
      "unsqueeze fN: torch.Size([1, 16, 256])\n",
      "size of concat fM, fN: torch.Size([2, 16, 256])\n",
      "after softmax: torch.Size([2, 16, 256])\n",
      "separate fM: torch.Size([16, 256])\n",
      "separate fN: torch.Size([16, 256])\n",
      "size of fM after view: torch.Size([16, 256, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 256, 54, 54])\n",
      "--------------------------------------------------\n",
      "Res_layer_2\n",
      "first add: torch.Size([16, 512, 27, 27])\n",
      "add after poolings: torch.Size([16, 512])\n",
      "bifore first fc: torch.Size([16, 512])\n",
      "after first fc: torch.Size([16, 512])\n",
      "after second fc: torch.Size([16, 512])\n",
      "size of fM: torch.Size([16, 512])\n",
      "size of fN: torch.Size([16, 512])\n",
      "unsqueeze fM: torch.Size([1, 16, 512])\n",
      "unsqueeze fN: torch.Size([1, 16, 512])\n",
      "size of concat fM, fN: torch.Size([2, 16, 512])\n",
      "after softmax: torch.Size([2, 16, 512])\n",
      "separate fM: torch.Size([16, 512])\n",
      "separate fN: torch.Size([16, 512])\n",
      "size of fM after view: torch.Size([16, 512, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 512, 27, 27])\n",
      "--------------------------------------------------\n",
      "Res_layer_3\n",
      "first add: torch.Size([16, 1024, 14, 14])\n",
      "add after poolings: torch.Size([16, 1024])\n",
      "bifore first fc: torch.Size([16, 1024])\n",
      "after first fc: torch.Size([16, 1024])\n",
      "after second fc: torch.Size([16, 1024])\n",
      "size of fM: torch.Size([16, 1024])\n",
      "size of fN: torch.Size([16, 1024])\n",
      "unsqueeze fM: torch.Size([1, 16, 1024])\n",
      "unsqueeze fN: torch.Size([1, 16, 1024])\n",
      "size of concat fM, fN: torch.Size([2, 16, 1024])\n",
      "after softmax: torch.Size([2, 16, 1024])\n",
      "separate fM: torch.Size([16, 1024])\n",
      "separate fN: torch.Size([16, 1024])\n",
      "size of fM after view: torch.Size([16, 1024, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 1024, 14, 14])\n",
      "--------------------------------------------------\n",
      "Res_layer_4\n",
      "first add: torch.Size([16, 2048, 7, 7])\n",
      "add after poolings: torch.Size([16, 2048])\n",
      "bifore first fc: torch.Size([16, 2048])\n",
      "after first fc: torch.Size([16, 2048])\n",
      "after second fc: torch.Size([16, 2048])\n",
      "size of fM: torch.Size([16, 2048])\n",
      "size of fN: torch.Size([16, 2048])\n",
      "unsqueeze fM: torch.Size([1, 16, 2048])\n",
      "unsqueeze fN: torch.Size([1, 16, 2048])\n",
      "size of concat fM, fN: torch.Size([2, 16, 2048])\n",
      "after softmax: torch.Size([2, 16, 2048])\n",
      "separate fM: torch.Size([16, 2048])\n",
      "separate fN: torch.Size([16, 2048])\n",
      "size of fM after view: torch.Size([16, 2048, 1, 1])\n",
      "shape of Fo is: torch.Size([16, 2048, 7, 7])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_names = ['ct_image', 'mutex_image']\n",
    "output_names = ['Fo', 'Fom']\n",
    "torch.onnx.export(model, (torch.randn(16, 3, 224, 224), torch.randn(16, 3, 224, 224)), 'final_model.onnx', input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06cbe5-8b3b-4828-aebd-b6edadbebabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab235d3-014d-4aae-9685-05e203da265a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baab852-86d5-46ba-b353-db08ed5b505b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe8411-78b7-4e8a-98e5-a5396b4c3ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
